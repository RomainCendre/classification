{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rcendre/classification')\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  \n",
    "from numpy import array, ones, maximum\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from toolbox.models.builtin import Applications\n",
    "from toolbox.classification.common import IO, Tools, Folds\n",
    "from toolbox.classification.parameters import Settings, Dermatology\n",
    "from toolbox.transforms.labels import OrderedEncoder\n",
    "from toolbox.views.common import Views, ViewsTools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = 4\n",
    "settings = Settings.get_default_dermatology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Dermatology.images(modality='Microscopy', data_type='Full', use_unknown=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform groups\n",
    "group_encoder = LabelEncoder().fit(array(inputs['ID_Patient'].tolist()))\n",
    "Tools.transform(inputs, {'datum': 'ID_Patient'}, group_encoder, 'GroupEncode')\n",
    "# Transform labels\n",
    "label_encoder = OrderedEncoder().fit(['Normal', 'Benign', 'Malignant'])\n",
    "Tools.transform(inputs, {'datum': 'Label'}, label_encoder, 'LabelEncode')\n",
    "# Make folds\n",
    "Folds.build_group_folds(inputs, {'datum': 'Datum', 'label_encode': 'LabelEncode', 'group': 'GroupEncode'}, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionnal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced = {'batch_size': 8,\n",
    "            'epochs' : 15,\n",
    "            'rotation_range': 45,\n",
    "            'width_shift_range': 0.2,\n",
    "            'height_shift_range': 0.2,\n",
    "            'horizontal_flip': True,\n",
    "            'vertical_flip': True}\n",
    "\n",
    "model = Applications.get_fine_tuning(3, 0, -1, architecture='ResNet', pooling='max', additional=advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5431 images belonging to 3 classes.\n",
      "Pre-training...\n",
      "WARNING:tensorflow:From /home/rcendre/classification/toolbox/models/models.py:807: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 679 steps\n",
      "Epoch 1/15\n",
      "679/679 [==============================] - 1167s 2s/step - loss: 8.7839 - accuracy: 0.4542\n",
      "Epoch 2/15\n",
      "679/679 [==============================] - 1161s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 3/15\n",
      "679/679 [==============================] - 1183s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 4/15\n",
      "679/679 [==============================] - 1215s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 5/15\n",
      "679/679 [==============================] - 1172s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 6/15\n",
      "679/679 [==============================] - 1162s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 7/15\n",
      "679/679 [==============================] - 1165s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 8/15\n",
      "679/679 [==============================] - 1163s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 9/15\n",
      "679/679 [==============================] - 1161s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 10/15\n",
      "679/679 [==============================] - 1167s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 11/15\n",
      "679/679 [==============================] - 1162s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 12/15\n",
      "679/679 [==============================] - 1165s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 13/15\n",
      "679/679 [==============================] - 1163s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 14/15\n",
      "679/679 [==============================] - 1164s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 15/15\n",
      "679/679 [==============================] - 1168s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Final-training...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 679 steps\n",
      "Epoch 1/15\n",
      "679/679 [==============================] - 1194s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 2/15\n",
      "679/679 [==============================] - 1193s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 3/15\n",
      "679/679 [==============================] - 1188s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 4/15\n",
      "679/679 [==============================] - 1186s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 5/15\n",
      "679/679 [==============================] - 1185s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 6/15\n",
      "679/679 [==============================] - 1187s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 7/15\n",
      "679/679 [==============================] - 1189s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 8/15\n",
      "679/679 [==============================] - 1184s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 9/15\n",
      "679/679 [==============================] - 1189s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 10/15\n",
      "679/679 [==============================] - 1185s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 11/15\n",
      "679/679 [==============================] - 1189s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 12/15\n",
      "679/679 [==============================] - 1193s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 13/15\n",
      "679/679 [==============================] - 1187s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 14/15\n",
      "679/679 [==============================] - 1184s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "Epoch 15/15\n",
      "679/679 [==============================] - 1191s 2s/step - loss: 8.7881 - accuracy: 0.4548\n",
      "WARNING:tensorflow:From /home/rcendre/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: FineVisualisation/assets\n"
     ]
    }
   ],
   "source": [
    "model = Tools.fit(inputs, {'datum': 'Datum', 'label_encode': 'LabelEncode'}, model)\n",
    "model.save('FineVisualisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Invalid reduction dimension (1 for input with 1 dimension(s) [Op:Mean]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cd0531bc9d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mguided_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   1910\u001b[0m       gen_math_ops.mean(\n\u001b[1;32m   1911\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m           name=name))\n\u001b[0m\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   5839\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5840\u001b[0m         return mean_eager_fallback(\n\u001b[0;32m-> 5841\u001b[0;31m             input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   5842\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5843\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean_eager_fallback\u001b[0;34m(input, axis, keep_dims, name, ctx)\u001b[0m\n\u001b[1;32m   5873\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tidx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5874\u001b[0m   _result = _execute.execute(b\"Mean\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 5875\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   5876\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5877\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/PythonGPU/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension (1 for input with 1 dimension(s) [Op:Mean]"
     ]
    }
   ],
   "source": [
    "model.load('FineVisualisation')\n",
    "grad_model = tf.keras.models.Model([model.model.inputs], [model.model.layers[-2].output, model.model.output])\n",
    "\n",
    "IMAGE_INDEX = 0\n",
    "CAT_CLASS_INDEX = 2\n",
    "image_path = inputs['Datum'][IMAGE_INDEX]\n",
    "img = tf.keras.preprocessing.image.load_img(image_path)\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_size = img.shape\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(np.array([img]))\n",
    "    loss = predictions[:, CAT_CLASS_INDEX]\n",
    "\n",
    "output = conv_outputs[0]\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "gate_f = tf.cast(output > 0, 'float32')\n",
    "gate_r = tf.cast(grads > 0, 'float32')\n",
    "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "cam = ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, :, i]\n",
    "\n",
    "cam = cv2.resize(cam.numpy(), img_size)\n",
    "cam = maximum(cam, 0)\n",
    "heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "cv2.imwrite(f'cam_{IMAGE_INDEX}.png', output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
