{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rcendre/classification')\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  \n",
    "from numpy import array, ones, maximum\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from toolbox.models.builtin import Applications\n",
    "from toolbox.classification.common import IO, Tools, Folds\n",
    "from toolbox.classification.parameters import Settings, Dermatology\n",
    "from toolbox.transforms.labels import OrderedEncoder\n",
    "from toolbox.views.common import Views, ViewsTools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = 4\n",
    "settings = Settings.get_default_dermatology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Dermatology.images(modality='Microscopy', data_type='Full', use_unknown=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform groups\n",
    "group_encoder = LabelEncoder().fit(array(inputs['ID_Patient'].tolist()))\n",
    "Tools.transform(inputs, {'datum': 'ID_Patient'}, group_encoder, 'GroupEncode')\n",
    "# Transform labels\n",
    "label_encoder = OrderedEncoder().fit(['Normal', 'Benign', 'Malignant'])\n",
    "Tools.transform(inputs, {'datum': 'Label'}, label_encoder, 'LabelEncode')\n",
    "# Make folds\n",
    "Folds.build_group_folds(inputs, {'datum': 'Datum', 'label_encode': 'LabelEncode', 'group': 'GroupEncode'}, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionnal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced = {'batch_size': 8,\n",
    "            'epochs' : 15,\n",
    "            'rotation_range': 45,\n",
    "            'width_shift_range': 0.2,\n",
    "            'height_shift_range': 0.2,\n",
    "            'horizontal_flip': True,\n",
    "            'vertical_flip': True}\n",
    "\n",
    "model = Applications.get_fine_tuning(3, 0, -1, architecture='ResNet', pooling='avg', additional=advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tools.fit(inputs, {'datum': 'Datum', 'label_encode': 'LabelEncode'}, model)\n",
    "model.save('FineTuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4073 images belonging to 3 classes.\n",
      "Pre-training...\n",
      "WARNING:tensorflow:From /home/rcendre/classification/toolbox/models/models.py:806: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 510 steps\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "model.load('FineTuned')\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(-1).output, model.output])\n",
    "\n",
    "IMAGE_INDEX = 0\n",
    "CAT_CLASS_INDEX = 2\n",
    "image_path = inputs['Datum'][IMAGE_INDEX]\n",
    "img = tf.keras.preprocessing.image.load_img(image_path)\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_size = img.shape\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(np.array([img]))\n",
    "    loss = predictions[:, CAT_CLASS_INDEX]\n",
    "\n",
    "output = conv_outputs[0]\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "gate_f = tf.cast(output > 0, 'float32')\n",
    "gate_r = tf.cast(grads > 0, 'float32')\n",
    "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "cam = ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, :, i]\n",
    "\n",
    "cam = cv2.resize(cam.numpy(), img_size)\n",
    "cam = maximum(cam, 0)\n",
    "heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "cv2.imwrite(f'cam_{IMAGE_INDEX}.png', output_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}