{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rcendre/classification')\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  \n",
    "from numpy import array, ones, maximum\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from toolbox.models.builtin import Applications\n",
    "from toolbox.classification.common import IO, Tools, Folds\n",
    "from toolbox.classification.parameters import Settings, Dermatology\n",
    "from toolbox.transforms.labels import OrderedEncoder\n",
    "from toolbox.views.common import Views, ViewsTools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = 4\n",
    "settings = Settings.get_default_dermatology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_patch = Dermatology.images(modality='Microscopy', data_type='Patch', use_unknown=False)\n",
    "inputs_full = Dermatology.images(modality='Microscopy', data_type='Full', use_unknown=False)\n",
    "prediction_file = f'Prediction_Curriculum.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform groups\n",
    "group_encoder = LabelEncoder().fit(array(inputs_full['ID_Patient'].tolist()))\n",
    "Tools.transform(inputs_full, {'datum': 'ID_Patient'}, group_encoder, 'GroupEncode')\n",
    "# Transform labels\n",
    "label_encoder = OrderedEncoder().fit(['Normal', 'Benign', 'Malignant'])\n",
    "Tools.transform(inputs_patch, {'datum': 'Label'}, label_encoder, 'LabelEncode')\n",
    "Tools.transform(inputs_full, {'datum': 'Label'}, label_encoder, 'LabelEncode')\n",
    "# Make folds\n",
    "Folds.build_group_folds(inputs_full, {'datum': 'Datum', 'label_encode': 'LabelEncode', 'group': 'GroupEncode'}, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionnal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "additionnal = {'batch_size': 8,\n",
    "            'epochs' : 15,\n",
    "            'shuffle': True,\n",
    "            'rotation_range': 45,\n",
    "            'width_shift_range': 0.1,\n",
    "            'height_shift_range': 0.1,\n",
    "            'horizontal_flip': True,\n",
    "            'vertical_flip': True,\n",
    "            'fill_mode': 'wrap'}\n",
    "\n",
    "model = Applications.get_fine_tuning(3, 0, -1, architecture='ResNet', pooling='max', activation='softmax', additional=additionnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5148 images belonging to 3 classes.\n",
      "Pre-training...\n",
      "WARNING:tensorflow:From /home/rcendre/classification/toolbox/models/models.py:807: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 644 steps\n",
      "Epoch 1/15\n",
      " 59/644 [=>............................] - ETA: 1:30 - loss: 4.4723 - accuracy: 0.5233"
     ]
    }
   ],
   "source": [
    "model = Tools.fit(inputs_patch, {'datum': 'Datum', 'label_encode': 'LabelEncode'}, model)\n",
    "model = Tools.fit(inputs, {'datum': 'Datum', 'label_encode': 'LabelEncode'}, model)\n",
    "model.save('CurriculumVisualisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('CurriculumVisualisation')\n",
    "\n",
    "from toolbox.views.images import GradCAM\n",
    "\n",
    "for IMAGE_INDEX in range(0,1000):\n",
    "    image_class = inputs['LabelEncode'][IMAGE_INDEX]\n",
    "    image_path = inputs['Datum'][IMAGE_INDEX]\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image_size = image.shape\n",
    "\n",
    "    # initialize our gradient class activation map and build the heatmap\n",
    "    cam = GradCAM(model.model, image_class)\n",
    "    heatmap = cam.compute_heatmap(image)\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "    cv2.imwrite(f'FineVis/{IMAGE_INDEX}_{image_class}.png', output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
